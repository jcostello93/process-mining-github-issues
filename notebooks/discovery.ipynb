{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run shared.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_noisy_events_log = pm4py.filter_event_attribute_values(\n",
    "    log,\n",
    "    \"concept:name\",\n",
    "    {\"subscribed\", \"unsubscribed\", \"referenced\", \"pinned\", \"unpinned\"},\n",
    "    retain=False,\n",
    ")\n",
    "filter_endpoints_and_noisy_events_log = filter_end_activities(\n",
    "    filter_noisy_events_log, {\"completed\", \"not_planned\"}\n",
    ")\n",
    "filter_event_attributes_log = filter_event_attribute_values(\n",
    "    log, \"concept:name\", {\"created\", \"labeled\", \"closed\"}, level=\"event\"\n",
    ")\n",
    "# filter_trace_attributes_log = filter_trace_attribute_values(log, 'case:Label', {'React Core Team'})\n",
    "filter_directly_follows_log = filter_directly_follows_relation(\n",
    "    log, [(\"closed\", \"commented\")], retain=True\n",
    ")\n",
    "filter_top_variants_log = filter_variants_top_k(log, 10)\n",
    "filter_endpoints_and_noisy_events_and_top_variants_log = filter_variants_top_k(\n",
    "    filter_endpoints_and_noisy_events_log, 10\n",
    ")\n",
    "filter_time_log = pm4py.filter_time_range(\n",
    "    log, \"2013-01-01 00:00:00\", \"2025-01-31 00:00:00\", mode=\"traces_contained\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log = log\n",
    "\n",
    "case_durations = get_all_case_durations(cell_log)\n",
    "median_case_duration = get_median_case_duration(cell_log)\n",
    "print(f\"Median case duration: {median_case_duration // 60 // 60 // 24} days\")\n",
    "single_case_duration = get_case_duration(\n",
    "    cell_log, cell_log[\"case:concept:name\"].iloc[0]\n",
    ")\n",
    "\n",
    "case_arrival_average = get_case_arrival_average(cell_log)\n",
    "print(\n",
    "    f\"Average distance between the arrival of two consecutive cases: {case_arrival_average // 60 // 60} hours\"\n",
    ")\n",
    "\n",
    "case_dispersion_ratio = get_case_dispersion_avg(cell_log)\n",
    "print(\n",
    "    f\"Average distance between the finishing of two consecutive cases: {case_dispersion_ratio // 60 // 60} hours\"\n",
    ")\n",
    "\n",
    "# TODO: Plot distribution to show how many events it takes to complete?\n",
    "activity_position_summary = get_activity_position_summary(cell_log, \"completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log = log\n",
    "\n",
    "view_events_distribution_graph(cell_log, distr_type=\"days_week\")\n",
    "view_events_distribution_graph(cell_log, distr_type=\"hours\")\n",
    "view_events_per_time_graph(cell_log)\n",
    "view_case_duration_graph(cell_log)\n",
    "\n",
    "if SAVE_VIS:\n",
    "    save_vis_events_distribution_graph(\n",
    "        cell_log, distr_type=\"days_week\", file_path=\"events_over_days_of_week.png\"\n",
    "    )\n",
    "    save_vis_events_distribution_graph(\n",
    "        cell_log, distr_type=\"hours\", file_path=\"events_over_hour_of_day.png\"\n",
    "    )\n",
    "    save_vis_events_per_time_graph(cell_log, file_path=\"events_over_time.png\")\n",
    "    save_vis_case_duration_graph(cell_log, file_path=\"case_duration.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "cell_log = log\n",
    "\n",
    "case_durations = cell_log.groupby(\"case:concept:name\")[\"time:timestamp\"].agg(\n",
    "    [\"min\", \"max\"]\n",
    ")\n",
    "case_durations.columns = [\"start_time\", \"end_time\"]\n",
    "\n",
    "case_durations = case_durations.sort_values(by=\"start_time\")\n",
    "\n",
    "event_points = pandas.DataFrame(\n",
    "    {\n",
    "        \"timestamp\": pandas.concat(\n",
    "            [case_durations[\"start_time\"], case_durations[\"end_time\"]]\n",
    "        ),\n",
    "        \"change\": [1] * len(case_durations)\n",
    "        + [-1] * len(case_durations),  # +1 for start, -1 for end\n",
    "    }\n",
    ")\n",
    "\n",
    "event_points = event_points.sort_values(by=\"timestamp\")\n",
    "event_points[\"active_cases\"] = event_points[\"change\"].cumsum()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(\n",
    "    event_points[\"timestamp\"],\n",
    "    event_points[\"active_cases\"],\n",
    "    marker=\"o\",\n",
    "    linestyle=\"-\",\n",
    "    color=\"blue\",\n",
    ")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Active Cases\")\n",
    "plt.title(\"Active Cases Over Time\")\n",
    "plt.grid()\n",
    "plt.savefig(\"active_cases_over_time.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(log[\"time:timestamp\"], bins=200, color=\"blue\", alpha=0.7, edgecolor=\"black\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Number of Events\")\n",
    "plt.title(\"Histogram of Events Over Time\")\n",
    "plt.savefig(\"histogram_events_over_time.png\")\n",
    "plt.grid()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log = log\n",
    "\n",
    "view_dotted_chart(cell_log, show_legend=False)\n",
    "\n",
    "if SAVE_VIS:\n",
    "    save_vis_dotted_chart(\n",
    "        cell_log, show_legend=False, file_path=\"dotted_line_chart.png\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log = filter_endpoints_and_noisy_events_and_top_variants_log\n",
    "\n",
    "noise_threshold = 0\n",
    "petri_net, initial_marking, final_marking = discover_petri_net_inductive(\n",
    "    cell_log, noise_threshold=noise_threshold\n",
    ")\n",
    "view_petri_net(petri_net, initial_marking, final_marking)\n",
    "fitness = fitness_token_based_replay(log, petri_net, initial_marking, final_marking)\n",
    "print(\"Fitness check: \")\n",
    "print(json.dumps(fitness, indent=4))\n",
    "soundness = check_soundness(petri_net, initial_marking, final_marking)\n",
    "\n",
    "gviz_frequency = petri_net_visualizer.apply(\n",
    "    petri_net,\n",
    "    initial_marking,\n",
    "    final_marking,\n",
    "    variant=petri_net_visualizer.Variants.FREQUENCY,\n",
    "    log=cell_log,\n",
    ")\n",
    "petri_net_visualizer.view(gviz_frequency)\n",
    "\n",
    "gviz_performance = petri_net_visualizer.apply(\n",
    "    petri_net,\n",
    "    initial_marking,\n",
    "    final_marking,\n",
    "    variant=petri_net_visualizer.Variants.PERFORMANCE,\n",
    "    log=log,\n",
    ")\n",
    "petri_net_visualizer.view(gviz_performance)\n",
    "\n",
    "\n",
    "if SAVE_VIS:\n",
    "    save_vis_petri_net(\n",
    "        petri_net, initial_marking, final_marking, file_path=\"petri_net.png\"\n",
    "    )\n",
    "    petri_net_visualizer.save(\n",
    "        gviz_frequency, output_file_path=\"petri_net_frequency.png\"\n",
    "    )\n",
    "    petri_net_visualizer.save(\n",
    "        gviz_performance, output_file_path=\"petri_net_performance.png\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log = filter_endpoints_and_noisy_events_and_top_variants_log\n",
    "\n",
    "noise_threshold = 0\n",
    "bpmn_diagram = discover_bpmn_inductive(cell_log, noise_threshold=noise_threshold)\n",
    "view_bpmn(bpmn_diagram)\n",
    "\n",
    "if SAVE_VIS:\n",
    "    save_vis_bpmn(bpmn_diagram, file_path=\"bpmn.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log = filter_endpoints_and_noisy_events_and_top_variants_log\n",
    "\n",
    "# Discover the frequency DFG using activites and paths to filter\n",
    "activities = get_event_attribute_values(cell_log, \"concept:name\")\n",
    "frequency_dfg, start_activities, end_activities = discover_dfg(cell_log)\n",
    "activities_perc = 0.99\n",
    "paths_perc = 0.99\n",
    "max_num_edges = 100\n",
    "frequency_dfg, start_activities, end_activities, activities = (\n",
    "    filter_dfg_on_activities_percentage(\n",
    "        frequency_dfg, start_activities, end_activities, activities, activities_perc\n",
    "    )\n",
    ")\n",
    "frequency_dfg, start_activities, end_activities, activities = (\n",
    "    filter_dfg_on_paths_percentage(\n",
    "        frequency_dfg, start_activities, end_activities, activities, paths_perc\n",
    "    )\n",
    ")\n",
    "view_dfg(\n",
    "    frequency_dfg,\n",
    "    start_activities,\n",
    "    end_activities,\n",
    "    max_num_edges=max_num_edges,\n",
    "    rankdir=\"LR\",\n",
    ")\n",
    "\n",
    "# Discover the performance DFG (does not support activites and paths filtering)\n",
    "performance_dfg, start_activities, end_activities = discover_performance_dfg(cell_log)\n",
    "\n",
    "# Uuse the frequency DFG to filter the performance DFG\n",
    "removal_list = []\n",
    "for edge in performance_dfg:\n",
    "    if edge not in frequency_dfg:\n",
    "        removal_list.append(edge)\n",
    "\n",
    "for edge in removal_list:\n",
    "    if edge in performance_dfg:\n",
    "        del performance_dfg[edge]\n",
    "\n",
    "view_performance_dfg(\n",
    "    performance_dfg,\n",
    "    start_activities,\n",
    "    end_activities,\n",
    "    aggregation_measure=\"sum\",\n",
    "    rankdir=\"LR\",\n",
    ")\n",
    "view_performance_dfg(\n",
    "    performance_dfg,\n",
    "    start_activities,\n",
    "    end_activities,\n",
    "    aggregation_measure=\"median\",\n",
    "    rankdir=\"LR\",\n",
    ")\n",
    "\n",
    "# dfg_time = clean_dfg_time.apply(cell_log)\n",
    "# gviz = timeline_gviz_generator.apply(frequency_dfg, dfg_time, parameters={'start_activities': start_activities, \"end_activities\": end_activities})\n",
    "# dfg_visualizer.view(gviz)\n",
    "\n",
    "if SAVE_VIS:\n",
    "    save_vis_dfg(\n",
    "        frequency_dfg,\n",
    "        start_activities,\n",
    "        end_activities,\n",
    "        max_num_edges=max_num_edges,\n",
    "        rankdir=\"TB\",\n",
    "        file_path=\"frequency_dfg.png\",\n",
    "    )\n",
    "    save_vis_performance_dfg(\n",
    "        performance_dfg,\n",
    "        start_activities,\n",
    "        end_activities,\n",
    "        aggregation_measure=\"sum\",\n",
    "        rankdir=\"TB\",\n",
    "        file_path=\"performance_dfg_sum.png\",\n",
    "    )\n",
    "    save_vis_performance_dfg(\n",
    "        performance_dfg,\n",
    "        start_activities,\n",
    "        end_activities,\n",
    "        aggregation_measure=\"median\",\n",
    "        rankdir=\"TB\",\n",
    "        file_path=\"performance_dfg_median.png\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log = filter_endpoints_and_noisy_events_log\n",
    "\n",
    "# Set up properties (this is similar to what your get_all_case_durations function does)\n",
    "properties = {\n",
    "    \"business_hours\": False,\n",
    "    # include other properties if needed\n",
    "}\n",
    "\n",
    "# Get the cases description. This returns a dictionary where each key is a case ID and each value is a dictionary\n",
    "# containing keys like 'startTime', 'endTime', 'caseDuration', etc.\n",
    "cases_description = case_statistics.get_cases_description(\n",
    "    cell_log, parameters=properties\n",
    ")\n",
    "\n",
    "# Prepare lists for plotting\n",
    "start_times = []\n",
    "durations = []\n",
    "\n",
    "for case_id, desc in cases_description.items():\n",
    "    # Make sure the description contains the needed fields\n",
    "    if \"startTime\" in desc and \"caseDuration\" in desc:\n",
    "        start_times.append(desc[\"startTime\"])\n",
    "        durations.append(desc[\"caseDuration\"] // 60 // 60 // 24)  # typically in seconds\n",
    "\n",
    "# Plot the durations over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(start_times, durations, alpha=0.6)\n",
    "plt.xlabel(\"Case Start Time\")\n",
    "plt.ylabel(\"Case Duration (days)\")\n",
    "plt.title(\"Case Durations Over Time\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
