{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run shared.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log = log.copy()\n",
    "\n",
    "case_durations = pm4py.get_all_case_durations(cell_log)\n",
    "median_case_duration = get_median_case_duration(cell_log)\n",
    "print(f\"Median case duration: {median_case_duration // 60 // 60 // 24} days\")\n",
    "single_case_duration = pm4py.get_case_duration(\n",
    "    cell_log, cell_log[\"case:concept:name\"].iloc[0]\n",
    ")\n",
    "\n",
    "case_arrival_average = pm4py.get_case_arrival_average(cell_log)\n",
    "print(\n",
    "    f\"Average distance between the arrival of two consecutive cases: {case_arrival_average // 60 // 60} hours\"\n",
    ")\n",
    "\n",
    "case_dispersion_ratio = get_case_dispersion_avg(cell_log)\n",
    "print(\n",
    "    f\"Average distance between the finishing of two consecutive cases: {case_dispersion_ratio // 60 // 60} hours\"\n",
    ")\n",
    "\n",
    "activity_position_summary = pm4py.get_activity_position_summary(cell_log, \"completed\")\n",
    "variants = pm4py.statistics.variants.pandas.get.get_variants_count(\n",
    "    filter_endpoints_events_log\n",
    ")\n",
    "sorted_variants = sorted(variants.items(), key=lambda item: item[1], reverse=True)\n",
    "num_variants = 10\n",
    "for k, v in sorted_variants[:num_variants]:\n",
    "    print(k, v)\n",
    "\n",
    "sorted_variants = sorted(variants.items(), key=lambda item: item[1], reverse=True)\n",
    "top_variants = sorted_variants[:num_variants]\n",
    "\n",
    "labels = [\" -> \".join(k) for k, v in top_variants]\n",
    "counts = [v for k, v in top_variants]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(labels[::-1], counts[::-1])  # Reverse for better visualization\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Variant\")\n",
    "plt.title(\"Top 10 Process Variants\")\n",
    "\n",
    "if SAVE_VIS:\n",
    "    plt.savefig(\"top_variants\")\n",
    "\n",
    "if VIEW_VIS:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log = filter_bot.copy()\n",
    "\n",
    "# Convert timestamp column to datetime\n",
    "cell_log[\"time:timestamp\"] = pandas.to_datetime(cell_log[\"time:timestamp\"])\n",
    "\n",
    "# Count occurrences of events per user\n",
    "top_users = cell_log[\"org:resource\"].value_counts().head(10).index  # Get top 10 users\n",
    "\n",
    "# Filter dataset to include only top users\n",
    "filtered_cell_log = cell_log[cell_log[\"org:resource\"].isin(top_users)]\n",
    "\n",
    "# Group by time and user\n",
    "grouped_df = (\n",
    "    filtered_cell_log.groupby(\n",
    "        [filtered_cell_log[\"time:timestamp\"].dt.to_period(\"M\"), \"org:resource\"]\n",
    "    )\n",
    "    .size()\n",
    "    .unstack()\n",
    ")\n",
    "\n",
    "# Plot\n",
    "grouped_df.plot(kind=\"line\", figsize=(12, 6), marker=\"o\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Event Count\")\n",
    "plt.title(\"Top Users Event Distribution Over Time\")\n",
    "plt.legend(title=\"User\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "\n",
    "if SAVE_VIS:\n",
    "    plt.savefig(\"top_users_over_time\")\n",
    "\n",
    "if VIEW_VIS:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log = log.copy()\n",
    "\n",
    "cell_log[\"time:timestamp\"] = pandas.to_datetime(cell_log[\"time:timestamp\"])\n",
    "grouped_df = (\n",
    "    cell_log.groupby([cell_log[\"time:timestamp\"].dt.to_period(\"M\"), \"concept:name\"])\n",
    "    .size()\n",
    "    .unstack()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "grouped_df.plot(kind=\"line\", marker=\"o\", figsize=(12, 6))\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Event Frequency\")\n",
    "plt.title(\"Event Frequency Over Time\")\n",
    "plt.legend(title=\"Event\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "\n",
    "if SAVE_VIS:\n",
    "    plt.savefig(\"event_frequency_over_time_by_event\")\n",
    "\n",
    "if VIEW_VIS:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log = filter_endpoints_events_log.copy()\n",
    "\n",
    "cell_log[\"time:timestamp\"] = pandas.to_datetime(cell_log[\"time:timestamp\"])\n",
    "event_log = pm4py.convert_to_event_log(cell_log)\n",
    "case_endings = []\n",
    "for trace in event_log:\n",
    "    last_event = trace[-1]  # Get the last event in the case\n",
    "    case_endings.append(\n",
    "        {\n",
    "            \"time:timestamp\": last_event[\"time:timestamp\"],\n",
    "            \"concept:name\": last_event[\"concept:name\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "endings_df = pandas.DataFrame(case_endings)\n",
    "endings_df[\"time:timestamp\"] = pandas.to_datetime(endings_df[\"time:timestamp\"])\n",
    "endings_df[\"period\"] = endings_df[\"time:timestamp\"].dt.to_period(\"M\")  # Group by month\n",
    "\n",
    "summary = endings_df.groupby([\"period\", \"concept:name\"]).size().unstack(fill_value=0)\n",
    "summary[\"total\"] = summary.sum(axis=1)\n",
    "summary[\"completed_pct\"] = summary.get(\"completed\", 0) / summary[\"total\"] * 100\n",
    "summary[\"not_planned_pct\"] = summary.get(\"not_planned\", 0) / summary[\"total\"] * 100\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(\n",
    "    summary.index.astype(str), summary[\"completed_pct\"], marker=\"o\", label=\"Completed\"\n",
    ")\n",
    "plt.plot(\n",
    "    summary.index.astype(str),\n",
    "    summary[\"not_planned_pct\"],\n",
    "    marker=\"o\",\n",
    "    label=\"Not Planned\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Percentage of Cases\")\n",
    "plt.title('Percentage of Cases Ending in \"Completed\" vs \"Not Planned\" Over Time')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log = filter_bot.copy()\n",
    "\n",
    "if VIEW_VIS:\n",
    "    pm4py.view_events_distribution_graph(cell_log, distr_type=\"days_week\")\n",
    "    pm4py.view_events_distribution_graph(cell_log, distr_type=\"hours\")\n",
    "    pm4py.view_events_per_time_graph(cell_log)\n",
    "    pm4py.view_case_duration_graph(cell_log)\n",
    "\n",
    "if SAVE_VIS:\n",
    "    pm4py.save_vis_events_distribution_graph(\n",
    "        cell_log, distr_type=\"days_week\", file_path=\"events_over_days_of_week.png\"\n",
    "    )\n",
    "    pm4py.save_vis_events_distribution_graph(\n",
    "        cell_log, distr_type=\"hours\", file_path=\"events_over_hour_of_day.png\"\n",
    "    )\n",
    "    pm4py.save_vis_events_per_time_graph(cell_log, file_path=\"events_over_time.png\")\n",
    "    pm4py.save_vis_case_duration_graph(cell_log, file_path=\"case_duration.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "cell_log = filter_bot_endpoints_noisy_events_top_variants_log.copy()\n",
    "\n",
    "case_durations = cell_log.groupby(\"case:concept:name\")[\"time:timestamp\"].agg(\n",
    "    [\"min\", \"max\"]\n",
    ")\n",
    "case_durations.columns = [\"start_time\", \"end_time\"]\n",
    "case_durations = case_durations.sort_values(by=\"start_time\")\n",
    "\n",
    "event_points = pandas.DataFrame(\n",
    "    {\n",
    "        \"timestamp\": pandas.concat(\n",
    "            [case_durations[\"start_time\"], case_durations[\"end_time\"]]\n",
    "        ),\n",
    "        \"change\": [1] * len(case_durations)\n",
    "        + [-1] * len(case_durations),  # +1 for start, -1 for end\n",
    "    }\n",
    ")\n",
    "\n",
    "event_points = event_points.sort_values(by=\"timestamp\")\n",
    "event_points[\"active_cases\"] = event_points[\"change\"].cumsum()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(\n",
    "    event_points[\"timestamp\"],\n",
    "    event_points[\"active_cases\"],\n",
    "    marker=\"o\",\n",
    "    linestyle=\"-\",\n",
    "    color=\"blue\",\n",
    ")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Active Cases\")\n",
    "plt.title(\"Active Cases Over Time\")\n",
    "plt.grid()\n",
    "\n",
    "if SAVE_VIS:\n",
    "    plt.savefig(\"active_cases_over_time.png\")\n",
    "\n",
    "if VIEW_VIS:\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(log[\"time:timestamp\"], bins=200, color=\"blue\", alpha=0.7, edgecolor=\"black\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Number of Events\")\n",
    "plt.title(\"Histogram of Events Over Time\")\n",
    "plt.grid()\n",
    "\n",
    "if SAVE_VIS:\n",
    "    plt.savefig(\"histogram_events_over_time.png\")\n",
    "\n",
    "if VIEW_VIS:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log = pm4py.sample_cases(\n",
    "    log, num_cases=len(log[\"case:concept:name\"].unique()) // 3\n",
    ")\n",
    "\n",
    "if VIEW_VIS:\n",
    "    pm4py.view_dotted_chart(cell_log, show_legend=False)\n",
    "\n",
    "if SAVE_VIS:\n",
    "    pm4py.save_vis_dotted_chart(\n",
    "        cell_log, show_legend=False, file_path=\"dotted_line_chart.png\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log = filter_endpoints_and_noisy_events_and_top_variants_log\n",
    "\n",
    "noise_threshold = 0.5\n",
    "petri_net, initial_marking, final_marking = pm4py.discover_petri_net_inductive(\n",
    "    cell_log, noise_threshold=noise_threshold\n",
    ")\n",
    "\n",
    "if VIEW_VIS:\n",
    "    pm4py.view_petri_net(petri_net, initial_marking, final_marking)\n",
    "\n",
    "# fitness = pm4py.fitness_token_based_replay(\n",
    "#     log, petri_net, initial_marking, final_marking\n",
    "# )\n",
    "# simplicity = pm4py.analysis.simplicity_petri_net(\n",
    "#     petri_net, initial_marking, final_marking\n",
    "# )\n",
    "# precision = pm4py.precision_token_based_replay(\n",
    "#     log, petri_net, initial_marking, final_marking\n",
    "# )\n",
    "# generalization = pm4py.algo.evaluation.generalization.algorithm.apply(\n",
    "#     log, petri_net, initial_marking, final_marking\n",
    "# )\n",
    "# soundness = pm4py.check_soundness(petri_net, initial_marking, final_marking)\n",
    "\n",
    "\n",
    "# print(\"Evaluate model: \")\n",
    "# print(f\"percentage_of_fitting_traces {fitness['percentage_of_fitting_traces']}\")\n",
    "# print(f\"average_trace_fitness {fitness['average_trace_fitness']}\")\n",
    "# print(f\"log_fitness {fitness['log_fitness']}\")\n",
    "# print(f\"simplicity: {simplicity}\")\n",
    "# print(f\"precision: {precision}\")\n",
    "# print(f\"generalization: {generalization}\")\n",
    "\n",
    "gviz_frequency = petri_net_visualizer.apply(\n",
    "    petri_net,\n",
    "    initial_marking,\n",
    "    final_marking,\n",
    "    variant=petri_net_visualizer.Variants.FREQUENCY,\n",
    "    log=cell_log,\n",
    ")\n",
    "\n",
    "if VIEW_VIS:\n",
    "    petri_net_visualizer.view(gviz_frequency)\n",
    "\n",
    "gviz_performance = petri_net_visualizer.apply(\n",
    "    petri_net,\n",
    "    initial_marking,\n",
    "    final_marking,\n",
    "    variant=petri_net_visualizer.Variants.PERFORMANCE,\n",
    "    log=log,\n",
    ")\n",
    "\n",
    "if VIEW_VIS:\n",
    "    petri_net_visualizer.view(gviz_performance)\n",
    "\n",
    "\n",
    "if SAVE_VIS:\n",
    "    pm4py.save_vis_petri_net(\n",
    "        petri_net, initial_marking, final_marking, file_path=\"petri_net.png\"\n",
    "    )\n",
    "    petri_net_visualizer.save(\n",
    "        gviz_frequency, output_file_path=\"petri_net_frequency.png\"\n",
    "    )\n",
    "    petri_net_visualizer.save(\n",
    "        gviz_performance, output_file_path=\"petri_net_performance.png\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log = filter_endpoints_and_noisy_events_and_top_variants_log\n",
    "\n",
    "noise_threshold = 0\n",
    "bpmn_diagram = pm4py.discover_bpmn_inductive(cell_log, noise_threshold=noise_threshold)\n",
    "\n",
    "if VIEW_VIS:\n",
    "    pm4py.view_bpmn(bpmn_diagram)\n",
    "\n",
    "if SAVE_VIS:\n",
    "    pm4py.save_vis_bpmn(bpmn_diagram, file_path=\"bpmn.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log = filter_endpoints_and_noisy_events_and_top_variants_log.copy()\n",
    "\n",
    "# Discover the frequency DFG using activites and paths to filter\n",
    "activities = pm4py.get_event_attribute_values(log, \"concept:name\")\n",
    "print(activities)\n",
    "frequency_dfg, start_activities, end_activities = pm4py.discover_dfg(cell_log)\n",
    "activities_perc = 0.95\n",
    "paths_perc = 0.95\n",
    "max_num_edges = 100\n",
    "frequency_dfg, start_activities, end_activities, activities = (\n",
    "    filter_dfg_on_activities_percentage(\n",
    "        frequency_dfg, start_activities, end_activities, activities, activities_perc\n",
    "    )\n",
    ")\n",
    "frequency_dfg, start_activities, end_activities, activities = (\n",
    "    filter_dfg_on_paths_percentage(\n",
    "        frequency_dfg, start_activities, end_activities, activities, paths_perc\n",
    "    )\n",
    ")\n",
    "\n",
    "# dfg_time = clean_dfg_time.apply(cell_log)\n",
    "# gviz = timeline_gviz_generator.apply(frequency_dfg, dfg_time, parameters={'max_no_of_edges_in_diagram': 10, 'start_activities': start_activities, \"end_activities\": end_activities})\n",
    "# dfg_visualizer.view(gviz)\n",
    "\n",
    "if VIEW_VIS:\n",
    "    pm4py.view_dfg(\n",
    "        frequency_dfg,\n",
    "        start_activities,\n",
    "        end_activities,\n",
    "        max_num_edges=max_num_edges,\n",
    "        rankdir=\"LR\",\n",
    "    )\n",
    "\n",
    "# Discover the performance DFG (does not support activites and paths filtering)\n",
    "performance_dfg, start_activities, end_activities = pm4py.discover_performance_dfg(\n",
    "    cell_log\n",
    ")\n",
    "\n",
    "# Uuse the frequency DFG to filter the performance DFG\n",
    "removal_list = []\n",
    "for edge in performance_dfg:\n",
    "    if edge not in frequency_dfg:\n",
    "        removal_list.append(edge)\n",
    "\n",
    "for edge in removal_list:\n",
    "    if edge in performance_dfg:\n",
    "        del performance_dfg[edge]\n",
    "\n",
    "if VIEW_VIS:\n",
    "    pm4py.view_performance_dfg(\n",
    "        performance_dfg,\n",
    "        start_activities,\n",
    "        end_activities,\n",
    "        aggregation_measure=\"sum\",\n",
    "        rankdir=\"LR\",\n",
    "    )\n",
    "\n",
    "    pm4py.view_performance_dfg(\n",
    "        performance_dfg,\n",
    "        start_activities,\n",
    "        end_activities,\n",
    "        aggregation_measure=\"median\",\n",
    "        rankdir=\"LR\",\n",
    "    )\n",
    "\n",
    "if SAVE_VIS:\n",
    "    pm4py.save_vis_dfg(\n",
    "        frequency_dfg,\n",
    "        start_activities,\n",
    "        end_activities,\n",
    "        max_num_edges=max_num_edges,\n",
    "        rankdir=\"TB\",\n",
    "        file_path=\"frequency_dfg.png\",\n",
    "    )\n",
    "    pm4py.save_vis_performance_dfg(\n",
    "        performance_dfg,\n",
    "        start_activities,\n",
    "        end_activities,\n",
    "        aggregation_measure=\"sum\",\n",
    "        rankdir=\"TB\",\n",
    "        file_path=\"performance_dfg_sum.png\",\n",
    "    )\n",
    "    pm4py.save_vis_performance_dfg(\n",
    "        performance_dfg,\n",
    "        start_activities,\n",
    "        end_activities,\n",
    "        aggregation_measure=\"median\",\n",
    "        rankdir=\"TB\",\n",
    "        file_path=\"performance_dfg_median.png\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log = filter_bot_endpoints_noisy_events_top_variants_log.copy()\n",
    "\n",
    "cell_log = cell_log[~cell_log[\"concept:name\"].str.contains(\"commented\")]\n",
    "\n",
    "\n",
    "properties = {\n",
    "    \"business_hours\": False,\n",
    "}\n",
    "\n",
    "cases_description = case_statistics.get_cases_description(\n",
    "    cell_log, parameters=properties\n",
    ")\n",
    "\n",
    "\n",
    "start_times = []\n",
    "durations = []\n",
    "\n",
    "for case_id, desc in cases_description.items():\n",
    "    if \"startTime\" in desc and \"caseDuration\" in desc:\n",
    "        start_times.append(desc[\"startTime\"])\n",
    "        durations.append(desc[\"caseDuration\"] // 60 // 60 // 24)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(start_times, durations, alpha=0.6)\n",
    "plt.xlabel(\"Case Start Time\")\n",
    "plt.ylabel(\"Case Duration (days)\")\n",
    "plt.title(\"Case Durations Over Time\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "if SAVE_VIS:\n",
    "    plt.savefig(\"case_durations_over_time\")\n",
    "\n",
    "if VIEW_VIS:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log = log.copy()\n",
    "\n",
    "# Identify first event per case (assuming case ID column is \"case:concept:name\")\n",
    "first_event = (\n",
    "    cell_log.groupby(\"case:concept:name\")[\"time:timestamp\"].min().reset_index()\n",
    ")\n",
    "first_event = first_event.rename(columns={\"time:timestamp\": \"first_event_time\"})\n",
    "\n",
    "maintainer_roles = {\"owner\", \"member\", \"collaborator\"}\n",
    "first_response_log = cell_log[\n",
    "    ~cell_log[\"concept:name\"].str.contains(\"created\", case=False, na=False)\n",
    "]\n",
    "df_maintainer = first_response_log[\n",
    "    first_response_log[\"author_association\"].isin(maintainer_roles)\n",
    "]\n",
    "first_response = (\n",
    "    df_maintainer.groupby(\"case:concept:name\")[\"time:timestamp\"].min().reset_index()\n",
    ")\n",
    "first_response = first_response.rename(\n",
    "    columns={\"time:timestamp\": \"first_response_time\"}\n",
    ")\n",
    "\n",
    "merged_df = first_event.merge(first_response, on=\"case:concept:name\", how=\"inner\")\n",
    "merged_df[\"response_time\"] = (\n",
    "    merged_df[\"first_response_time\"] - merged_df[\"first_event_time\"]\n",
    ").dt.total_seconds() / 3600  # Convert to hours\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(merged_df[\"response_time\"], bins=10000, edgecolor=\"black\")\n",
    "plt.xlabel(\"Time Until First Response (hours)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Time Until First Response from Maintainer\")\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([0, 3 * 24])\n",
    "\n",
    "if VIEW_VIS:\n",
    "    plt.show()\n",
    "\n",
    "if VIEW_VIS:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log = log\n",
    "\n",
    "# Convert timestamp columns to datetime\n",
    "cell_log[\"time:timestamp\"] = pandas.to_datetime(cell_log[\"time:timestamp\"])\n",
    "\n",
    "# cell_log = cell_log[~cell_log['concept:name'].str.contains(\"not_planned\", case=False, na=False)]\n",
    "\n",
    "# Identify first event per case\n",
    "first_event = (\n",
    "    cell_log.groupby(\"case:concept:name\")[\"time:timestamp\"].min().reset_index()\n",
    ")\n",
    "first_event = first_event.rename(columns={\"time:timestamp\": \"first_event_time\"})\n",
    "\n",
    "# Identify first response from a maintainer\n",
    "maintainer_roles = {\"collaborator\"}\n",
    "df_maintainer = cell_log[cell_log[\"author_association\"].isin(maintainer_roles)]\n",
    "\n",
    "first_response = (\n",
    "    df_maintainer.groupby(\"case:concept:name\")[\"time:timestamp\"].min().reset_index()\n",
    ")\n",
    "first_response = first_response.rename(\n",
    "    columns={\"time:timestamp\": \"first_response_time\"}\n",
    ")\n",
    "\n",
    "# Merge datasets\n",
    "merged_df = first_event.merge(first_response, on=\"case:concept:name\", how=\"inner\")\n",
    "merged_df[\"response_time\"] = (\n",
    "    merged_df[\"first_response_time\"] - merged_df[\"first_event_time\"]\n",
    ").dt.total_seconds() / 3600  # Convert to hours\n",
    "\n",
    "# Sort by first event time\n",
    "merged_df = merged_df.sort_values(\"first_event_time\")\n",
    "\n",
    "\n",
    "print(merged_df.nlargest(10, \"response_time\"))\n",
    "\n",
    "# Plot response time over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(merged_df[\"first_event_time\"], merged_df[\"response_time\"], alpha=0.6)\n",
    "plt.xlabel(\"Time of Issue Creation\")\n",
    "plt.ylabel(\"Time Until First Response (hours)\")\n",
    "plt.title(\"Time Until First Response Over Time\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "\n",
    "if VIEW_VIS:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log = filter_top_variants_log\n",
    "\n",
    "num_cases = 1000  # len(log)\n",
    "\n",
    "petri_net, initial_marking, final_marking = pm4py.discover_petri_net_inductive(\n",
    "    cell_log, noise_threshold=noise_threshold\n",
    ")\n",
    "pm4py.view_petri_net(petri_net, initial_marking, final_marking)\n",
    "\n",
    "parameters_tbr = {\n",
    "    token_based_replay_algorithm.Variants.TOKEN_REPLAY.value.Parameters.DISABLE_VARIANTS: True,\n",
    "    token_based_replay_algorithm.Variants.TOKEN_REPLAY.value.Parameters.ENABLE_PLTR_FITNESS: True,\n",
    "}\n",
    "\n",
    "replayed_traces, place_fitness, trans_fitness, unwanted_activities_from_replay = (\n",
    "    token_based_replay_algorithm.apply(\n",
    "        pm4py.sample_cases(filter_endpoints_events_log, num_cases=num_cases),\n",
    "        petri_net,\n",
    "        initial_marking,\n",
    "        final_marking,\n",
    "        parameters=parameters_tbr,\n",
    "    )\n",
    ")\n",
    "\n",
    "formatted_unwanted_activities = {}\n",
    "for trace in pm4py.convert.convert_to_event_log(log):\n",
    "    for event in trace:\n",
    "        activity_name = event[\"concept:name\"]\n",
    "\n",
    "        if activity_name in unwanted_activities_from_replay:\n",
    "            if activity_name not in formatted_unwanted_activities:\n",
    "                formatted_unwanted_activities[activity_name] = []\n",
    "            formatted_unwanted_activities[activity_name].append(trace)\n",
    "\n",
    "\n",
    "act_diagnostics = diagnose_from_notexisting_activities(\n",
    "    pm4py.sample_cases(filter_endpoints_events_log, num_cases=num_cases),\n",
    "    formatted_unwanted_activities,\n",
    ")\n",
    "sorted_items = sorted(\n",
    "    act_diagnostics.items(), key=lambda x: x[1][\"relative_throughput\"], reverse=True\n",
    ")\n",
    "\n",
    "print(\"For each problematic activity, diagnostics about case duration\")\n",
    "# Print the sorted elements\n",
    "for key, value in sorted_items:\n",
    "    print(f\"{key}: {json.dumps(value, indent=4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_log = pm4py.convert_to_event_log(pm4py.sample_cases(log, num_cases=10000))\n",
    "\n",
    "if VIEW_VIS:\n",
    "    pm4py.view_performance_spectrum(cell_log, [\"created\", \"not_planned\"])\n",
    "\n",
    "if SAVE_VIS:\n",
    "    pm4py.save_vis_performance_spectrum(\n",
    "        cell_log, [\"created\", \"not_planned\"], file_path=\"performance_spectrum.png\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "loga = pm4py.convert_to_event_log(\n",
    "    pm4py.filter_time_range(\n",
    "        log, \"2023-01-01 00:00:00\", \"2023-12-31 11:59:59\", mode=\"traces_contained\"\n",
    "    )\n",
    ")\n",
    "logb = pm4py.convert_to_event_log(\n",
    "    pm4py.filter_time_range(\n",
    "        log, \"2024-01-01 00:00:00\", \"2024-12-31 11:59:59\", mode=\"traces_contained\"\n",
    "    )\n",
    ")\n",
    "\n",
    "loga = pm4py.sample_cases(loga, num_cases=min(len(loga), len(logb)))\n",
    "logb = pm4py.sample_cases(logb, num_cases=min(len(loga), len(logb)))\n",
    "\n",
    "statistics = compare_element_usage_two_logs(\n",
    "    petri_net, initial_marking, final_marking, loga, logb\n",
    ")\n",
    "gviz = petri_net_visualizer.apply(\n",
    "    petri_net,\n",
    "    initial_marking,\n",
    "    final_marking,\n",
    "    variant=petri_net_visualizer.Variants.FREQUENCY,\n",
    "    aggregated_statistics=statistics,\n",
    ")\n",
    "\n",
    "if VIEW_VIS:\n",
    "    petri_net_visualizer.view(gviz)\n",
    "\n",
    "if SAVE_VIS:\n",
    "    petri_net_visualizer.save(gviz, output_file_path=\"compare_petri_nets_yearly.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
