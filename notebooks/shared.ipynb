{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pm4py\n",
    "from src.data_pipeline.s3 import fetch_file\n",
    "\n",
    "# Define repository and S3 bucket details\n",
    "OWNER = \"jcostello93\"\n",
    "REPO = \"node-red-contrib-node-reddit\"\n",
    "S3_BUCKET = \"process-mining-github-issues-staging\"\n",
    "\n",
    "# Dynamically get the project root directory (one level up from notebooks)\n",
    "NOTEBOOK_DIR = os.path.abspath(os.getcwd())  # Current notebook directory\n",
    "ROOT_DIR = os.path.dirname(NOTEBOOK_DIR)  # Move up one level to project root\n",
    "\n",
    "# Define the file path in the root directory\n",
    "file_name = f\"{OWNER}_{REPO}_event_log.xes\"\n",
    "file_path = os.path.join(ROOT_DIR, file_name)  # Store directly in the root folder\n",
    "\n",
    "# Fetch the file from S3 (if not present locally)\n",
    "local_file = fetch_file(file_path, S3_BUCKET, file_name)\n",
    "\n",
    "# Process the XES file if successfully downloaded\n",
    "if local_file:\n",
    "    log = pm4py.read_xes(local_file)\n",
    "    print(log.head())\n",
    "else:\n",
    "    print(\"Failed to fetch or process the XES file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pm4py\n",
    "\n",
    "from pm4py import check_soundness  # noqa: F401\n",
    "from pm4py import conformance_diagnostics_token_based_replay  # noqa: F401\n",
    "from pm4py import convert_to_event_log  # noqa: F401\n",
    "from pm4py import discover_activity_based_resource_similarity  # noqa: F401\n",
    "from pm4py import discover_dfg  # noqa: F401\n",
    "from pm4py import discover_heuristics_net  # noqa: F401\n",
    "from pm4py import discover_performance_dfg  # noqa: F401\n",
    "from pm4py import discover_petri_net_inductive  # noqa: F401\n",
    "from pm4py import filter_directly_follows_relation  # noqa: F401\n",
    "from pm4py import filter_end_activities  # noqa: F401\n",
    "from pm4py import filter_event_attribute_values  # noqa: F401\n",
    "from pm4py import filter_start_activities  # noqa: F401\n",
    "from pm4py import filter_trace_attribute_values  # noqa: F401\n",
    "from pm4py import filter_variants_top_k  # noqa: F401\n",
    "from pm4py import get_all_case_durations  # noqa: F401\n",
    "from pm4py import get_event_attribute_values  # noqa: F401\n",
    "from pm4py import sample_cases  # noqa: F401\n",
    "from pm4py import sample_events  # noqa: F401\n",
    "from pm4py import view_dfg  # noqa: F401\n",
    "from pm4py import view_heuristics_net  # noqa: F401\n",
    "from pm4py import view_performance_dfg  # noqa: F401\n",
    "from pm4py import view_petri_net  # noqa: F401\n",
    "\n",
    "from pm4py.algo.conformance.tokenreplay import algorithm as token_based_replay_algorithm  # noqa: F401\n",
    "from pm4py.algo.evaluation.replay_fitness import algorithm as replay_fitness_algorithm  # noqa: F401\n",
    "from pm4py.algo.evaluation.precision import algorithm as precision_evaluator_algorithm  # noqa: F401\n",
    "from pm4py.algo.discovery.dfg.variants import clean_time as clean_dfg_time  # noqa: F401\n",
    "from pm4py.algo.filtering.dfg.dfg_filtering import clean_dfg_based_on_noise_thresh  # noqa: F401\n",
    "from pm4py.algo.filtering.dfg.dfg_filtering import filter_dfg_on_activities_percentage  # noqa: F401\n",
    "from pm4py.algo.filtering.dfg.dfg_filtering import filter_dfg_on_paths_percentage  # noqa: F401\n",
    "from pm4py.algo.filtering.log.attributes import attributes_filter  # noqa: F401\n",
    "from pm4py.algo.organizational_mining.sna import util as sna_util  # noqa: F401\n",
    "from pm4py.algo.organizational_mining.sna import algorithm as sna_algorithm  # noqa: F401\n",
    "from pm4py.algo.organizational_mining.roles import algorithm as roles_algorithm  # noqa: F401\n",
    "\n",
    "from pm4py.statistics.traces.generic.log import case_statistics  # noqa: F401\n",
    "\n",
    "from pm4py.stats import get_case_duration  # noqa: F401\n",
    "from pm4py.stats import get_cycle_time  # noqa: F401\n",
    "from pm4py.stats import get_activity_position_summary  # noqa: F401\n",
    "from pm4py.stats import get_case_arrival_average  # noqa: F401\n",
    "\n",
    "from pm4py.util import variants_util  # noqa: F401\n",
    "\n",
    "from pm4py.visualization.dfg.variants import timeline as timeline_gviz_generator  # noqa: F401\n",
    "from pm4py.visualization.dfg import visualizer as dfg_visualizer  # noqa: F401\n",
    "from pm4py.visualization.petri_net import visualizer as petri_net_visualizer  # noqa: F401\n",
    "from pm4py.visualization.sna import visualizer as sna_vis  # noqa: F401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_threshold = 0\n",
    "petri_net, initial_marking, final_marking = discover_petri_net_inductive(\n",
    "    log, noise_threshold=noise_threshold\n",
    ")\n",
    "view_petri_net(petri_net, initial_marking, final_marking)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
