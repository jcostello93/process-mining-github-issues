{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pm4py\n",
    "from src.data_pipeline.s3 import fetch_file\n",
    "\n",
    "# Define repository and S3 bucket details\n",
    "OWNER = \"facebook\"\n",
    "REPO = \"react\"\n",
    "S3_BUCKET = \"process-mining-github-issues-staging\"\n",
    "VIEW_VIS = True\n",
    "SAVE_VIS = True\n",
    "\n",
    "# Dynamically get the project root directory (one level up from notebooks)\n",
    "NOTEBOOK_DIR = os.path.abspath(os.getcwd())  # Current notebook directory\n",
    "ROOT_DIR = os.path.dirname(NOTEBOOK_DIR)  # Move up one level to project root\n",
    "\n",
    "# Define the file path in the root directory\n",
    "file_name = f\"{OWNER}_{REPO}_event_log.xes\"\n",
    "file_path = os.path.join(ROOT_DIR, file_name)  # Store directly in the root folder\n",
    "\n",
    "# Fetch the file from S3 (if not present locally)\n",
    "local_file = fetch_file(file_path, S3_BUCKET, file_name)\n",
    "\n",
    "# Process the XES file if successfully downloaded\n",
    "if local_file:\n",
    "    log = pm4py.read_xes(local_file)\n",
    "    legacy_log = pm4py.read_xes(local_file, return_legacy_log_object=True)\n",
    "    print(log.head())\n",
    "else:\n",
    "    print(\"Failed to fetch or process the XES file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas\n",
    "import pm4py\n",
    "\n",
    "from pm4py.algo.conformance.tokenreplay import algorithm as token_based_replay_algorithm\n",
    "from pm4py.algo.conformance.tokenreplay.diagnostics import duration_diagnostics\n",
    "from pm4py.algo.evaluation.replay_fitness import algorithm as replay_fitness_algorithm\n",
    "from pm4py.algo.evaluation.precision import algorithm as precision_evaluator_algorithm\n",
    "from pm4py.algo.comparison.petrinet.element_usage_comparison import (\n",
    "    compare_element_usage_two_logs,\n",
    ")\n",
    "from pm4py.algo.discovery.dfg.variants import clean_time as clean_dfg_time\n",
    "from pm4py.algo.filtering.dfg.dfg_filtering import clean_dfg_based_on_noise_thresh\n",
    "from pm4py.algo.filtering.dfg.dfg_filtering import filter_dfg_on_activities_percentage\n",
    "from pm4py.algo.filtering.dfg.dfg_filtering import filter_dfg_on_paths_percentage\n",
    "from pm4py.algo.filtering.log.attributes import attributes_filter\n",
    "from pm4py.algo.organizational_mining.sna import util as sna_util\n",
    "from pm4py.algo.organizational_mining.sna import algorithm as sna_algorithm\n",
    "from pm4py.algo.organizational_mining.roles import algorithm as roles_algorithm\n",
    "\n",
    "\n",
    "from pm4py.statistics.traces.generic.log import case_statistics\n",
    "from pm4py.statistics.traces.generic.log.case_statistics import get_median_case_duration\n",
    "from pm4py.statistics.traces.generic.log.case_arrival import get_case_dispersion_avg\n",
    "\n",
    "from pm4py.stats import get_case_duration\n",
    "from pm4py.stats import get_cycle_time\n",
    "from pm4py.stats import get_activity_position_summary\n",
    "from pm4py.stats import get_case_arrival_average\n",
    "\n",
    "from pm4py.util import variants_util\n",
    "\n",
    "from pm4py.visualization.dfg.variants import timeline as timeline_gviz_generator\n",
    "from pm4py.visualization.dfg import visualizer as dfg_visualizer\n",
    "from pm4py.visualization.petri_net import visualizer as petri_net_visualizer\n",
    "from pm4py.visualization.sna import visualizer as sna_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_noisy_events_log = pm4py.filter_event_attribute_values(\n",
    "    log,\n",
    "    \"concept:name\",\n",
    "    {\"subscribed\", \"unsubscribed\", \"pinned\", \"unpinned\"},\n",
    "    retain=False,\n",
    "    level=\"event\",\n",
    ")\n",
    "filter_endpoints_events_log = pm4py.filter_end_activities(\n",
    "    log, {\"closed\", \"not_planned\"}\n",
    ")\n",
    "filter_endpoints_and_noisy_events_log = pm4py.filter_end_activities(\n",
    "    filter_noisy_events_log, {\"closed\", \"not_planned\"}\n",
    ")\n",
    "filter_event_attributes_log = pm4py.filter_event_attribute_values(\n",
    "    log, \"concept:name\", {\"created\", \"labeled\", \"closed\"}, level=\"event\"\n",
    ")\n",
    "# filter_trace_attributes_log = pm4py.filter_trace_attribute_values(log, 'case:Label', {'React Core Team'})\n",
    "filter_directly_follows_log = pm4py.filter_directly_follows_relation(\n",
    "    log, [(\"closed\", \"commented\")], retain=True\n",
    ")\n",
    "filter_top_variants_log = pm4py.filter_variants_top_k(log, 100)\n",
    "filter_endpoints_and_noisy_events_and_top_variants_log = pm4py.filter_variants_top_k(\n",
    "    filter_endpoints_and_noisy_events_log, 100\n",
    ")\n",
    "filter_time_log = pm4py.filter_time_range(\n",
    "    log, \"2023-01-01 00:00:00\", \"2025-01-31 00:00:00\", mode=\"traces_contained\"\n",
    ")\n",
    "\n",
    "filter_bot = log[~log[\"author_association\"].str.contains(\"bot\", case=False, na=False)]\n",
    "filter_bot_noisy_events_log = pm4py.filter_end_activities(\n",
    "    filter_bot, {\"closed\", \"not_planned\"}\n",
    ")\n",
    "filter_bot_endpoints_noisy_events_log = pm4py.filter_end_activities(\n",
    "    filter_bot_noisy_events_log, {\"closed\", \"not_planned\"}\n",
    ")\n",
    "filter_bot_endpoints_noisy_events_top_variants_log = pm4py.filter_variants_top_k(\n",
    "    filter_bot_endpoints_noisy_events_log, 10\n",
    ")\n",
    "\n",
    "# print(len(log.loc[~log['pr_merged_at'].isnull()]))\n",
    "filter_noisy_events_case_pr_merged = pm4py.filter_event_attribute_values(\n",
    "    filter_noisy_events_log, \"has_merged_pr\", {True}, retain=True, level=\"case\"\n",
    ")\n",
    "\n",
    "\n",
    "filter_noisy_events_case_pr_merged_endpoints = pm4py.filter_end_activities(\n",
    "    filter_noisy_events_case_pr_merged, {\"closed\", \"not_planned\"}\n",
    ")\n",
    "\n",
    "print(filter_noisy_events_case_pr_merged_endpoints)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
